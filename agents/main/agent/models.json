{
  "providers": {
    "qwen-portal": {
      "baseUrl": "https://portal.qwen.ai/v1",
      "api": "openai-completions",
      "models": [
        {
          "id": "coder-model",
          "name": "Qwen Coder",
          "reasoning": false,
          "input": [
            "text"
          ],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "contextWindow": 128000,
          "maxTokens": 8192
        },
        {
          "id": "vision-model",
          "name": "Qwen Vision",
          "reasoning": false,
          "input": [
            "text",
            "image"
          ],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "contextWindow": 128000,
          "maxTokens": 8192
        }
      ],
      "apiKey": "qwen-oauth"
    },
    "ollama": {
      "baseUrl": "http://127.0.0.1:11434",
      "api": "ollama",
      "models": [
        {
          "id": "nomic-embed-text:latest",
          "name": "nomic-embed-text:latest",
          "reasoning": false,
          "input": [
            "text"
          ],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "contextWindow": 128000,
          "maxTokens": 8192
        },
        {
          "id": "hf.co/mradermacher/Qwen3-4B-2507-Thinking-heretic-abliterated-uncensored-GGUF:Q4_K_M",
          "name": "hf.co/mradermacher/Qwen3-4B-2507-Thinking-heretic-abliterated-uncensored-GGUF:Q4_K_M",
          "reasoning": false,
          "input": [
            "text"
          ],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "contextWindow": 128000,
          "maxTokens": 8192
        },
        {
          "id": "senpaisama7/TROY:latest",
          "name": "senpaisama7/TROY:latest",
          "reasoning": false,
          "input": [
            "text"
          ],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "contextWindow": 128000,
          "maxTokens": 8192
        },
        {
          "id": "qwen3-8b-hivemind-uncensored:latest",
          "name": "qwen3-8b-hivemind-uncensored:latest",
          "reasoning": false,
          "input": [
            "text"
          ],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "contextWindow": 128000,
          "maxTokens": 8192
        },
        {
          "id": "hf.co/mradermacher/gemma-3-4b-it-heretic-uncensored-abliterated-Extreme-i1-GGUF:Q6_K",
          "name": "hf.co/mradermacher/gemma-3-4b-it-heretic-uncensored-abliterated-Extreme-i1-GGUF:Q6_K",
          "reasoning": false,
          "input": [
            "text"
          ],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "contextWindow": 128000,
          "maxTokens": 8192
        }
      ],
      "apiKey": "OLLAMA_API_KEY"
    },
    "nvidia": {
      "baseUrl": "https://integrate.api.nvidia.com/v1",
      "api": "openai-completions",
      "models": [
        {
          "id": "nvidia/llama-3.1-nemotron-70b-instruct",
          "name": "NVIDIA Llama 3.1 Nemotron 70B Instruct",
          "reasoning": false,
          "input": [
            "text"
          ],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "contextWindow": 131072,
          "maxTokens": 4096
        },
        {
          "id": "meta/llama-3.3-70b-instruct",
          "name": "Meta Llama 3.3 70B Instruct",
          "reasoning": false,
          "input": [
            "text"
          ],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "contextWindow": 131072,
          "maxTokens": 4096
        },
        {
          "id": "nvidia/mistral-nemo-minitron-8b-8k-instruct",
          "name": "NVIDIA Mistral NeMo Minitron 8B Instruct",
          "reasoning": false,
          "input": [
            "text"
          ],
          "cost": {
            "input": 0,
            "output": 0,
            "cacheRead": 0,
            "cacheWrite": 0
          },
          "contextWindow": 8192,
          "maxTokens": 2048
        }
      ],
      "apiKey": "NVIDIA_API_KEY"
    },
    "github-copilot": {
      "baseUrl": "https://api.individual.githubcopilot.com",
      "models": []
    }
  }
}
